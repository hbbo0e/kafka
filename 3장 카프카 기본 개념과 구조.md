> 카프카의 기본 개념과 구조를 다루고, 카프카의 처리량을 높이기 위해 설계된 분산 시스템, 페이지 캐시, 배치 전송 등을 살펴보고 주키퍼의 역할에 대해서 알아보자


# 3.1 카프카 기초 다지기

## 참고 - 카프카를 구성하는 주요 요소

1. 주키퍼 (ZooKeeper)
	: 아파치 프로젝트 애플리케이션 이름
	카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당한다.
2. 카프카 또는 카프카 클러스터 (Kafka cluster)
	: 아파치 프로젝트 애플리케이션 이름
	여러 대의 브로커를 구성한 클러스터를 의미한다.
3. 브로커 (broker)
	: 카프카 애플리케이션이 설치된 서버 또는 노드
4. 프로듀서
	: 카프카로 메시지를 보내는 역할을 하는 클라이언트 
5. 컨슈머
	: 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트
6. 토픽
	: 카프카는 메시지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유하다.
7. 파티션
	: 병렬 처리 및 고성능을 얻기 위해 하나읱 토픽을 여러 개로 나눈 것
8. 세그먼트
	: 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일
9. 메시지 또는 레코드
	: 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각

## 3.1.1 리플리케이션

> 리플리케이션 (replication)

: 각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에 분산시키는 동작
-> 이러한 동작 덕분에 하나의 브로커가 종료되더라도 카프카는 안정성을 유지할 수 있다.

> 토픽 생성 명령어

`replication-factor` 옵션 : 카프카 내 몇 개의 리플리케이션을 유지하겠다는 의미이다.
	replication-factor 가 1 이라면 리플리케이션이 1개 있다는 의미

![[Pasted image 20240614123538.png]]
	`peter-overview01` 토픽을 리플리케이션 팩터 수 3 으로 설정한 후 각 브로커에 배치된 상태
	(카프카에서 토픽이 리플리케이션 되는 것이 아니라 토픽의 파티션이 리플리케이션 되는 것이다.)

- 안정성을 목적으로 모든 토픽에 대해 각 3개의 리플리케이션으로 설정할 수 있다. 리플리케이션 팩터 수가 커지면 안정성은 높아지지만 그만큼 브로커 리소스를 많이 사용하게 된다.
-> 복제에 대한 오버헤드를 줄여서 최대한 브로커를 효율적으로 사용하는 것을 권장한다.

- 토픽 생성 시 효율적인 카프카 운영 기준
	1. 테스트나 개발 환경 -> 리플리케이션 팩터 수를 1로 설정
	2. 운영 환경 (로그성 메시지로서 약간의 유실 허용) -> 리플리케이션 팩터 수를 2로 설정
	3. 운영 환경 (유실 허용 안 됨) -> 리플리케이션 팩터 수를 3으로 설정


## 3.1.2 파티션

하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬 처리, 분산 처리가 가능하게 만든 것이다. 이렇게 나뉜 파티션 수만큼 컨슈머를 연결할 수 있다.

![[Pasted image 20240614142936.png]]
	카프카 클러스터에 있는 토픽을 파티션으로 나누었다.

파티션 수도 토픽을 생성할 때 옵션으로 설정하게 되는데, 기준이 다소 모호하다.
	각 메시지 크기나 초당 메시지 건수 등에 따라 달라지기도 한다.
	특히 파티션 수는 초기 생성 후 늘릴 수는 있지만 한 번 늘린 파티션 수는 절대 줄일 수가 없다.

## 3.1.3 세그먼트

프로듀서에 의해 브로커로 전송된 메시지는 토픽의 파티션에 저장되며, **각 메시지들은 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장된다**.


![[Pasted image 20240614143232.png]]
	각 파티션 별로 세그먼트를 나누었다.

> 정리

![[Pasted image 20240614143455.png]]
	1. 프로듀서는 카프카의 `peter-overview01` 토픽으로 메시지를 전송한다.
	2. `peter-overview01` 토픽은 파티션이 하나뿐이므로, 프로듀서로부터 받은 메시지를 파티션0의 세그먼트 로그 파일에 저장한다.
	3. 브로커의 세그먼트 로그 파일에 저장된 메시지는 컨슈머가 읽어갈 수 있다.
	4. 컨슈머는 `peter-overview01` 토픽을 컨슘해서 해당 토픽 내 파티션0의 세그먼트 로그 파일에서 메시지를 가져온다.



# 3.2 카프카의 핵심 개념

## 3.2.1 분산 시스템

**분산 시스템**은 네트워크 상에서 연결된 컴퓨터들의 그룹이며, 단일 시스템이 갖지 못한 높은 성능을 목표로 한다.

- 장점
	1. 하나의 서버 혹은 노드 등에서 장애가 발생했을 때 다른 서버 혹은 노드 등에서 대신 처리하므로 장애 대응이 탁월하다.
	2. 부하가 높은 경우에는 시스템 학장이 용이하다.

## 3.2.2 페이지 캐시

**페이지캐시**는 직접 디스크에 읽고 쓰는 대신 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리를 활용한다. ->디스크 I/O 에 대한 접근이 줄어들므로 성능을 높일 수 있다.

![[Pasted image 20240614144025.png]]

## 3.2.3 배치 전송 처리

수많은 통신이 발생할 때 이를 묶어서 처리하는 방식이다.
-> 네트워크 오버헤드를 줄일 수 있고, 더욱 빠르고 효율적으로 처리할 수 있다.

## 3.2.4 압축 전송

카프카는 메시지 전송 시 좀 더 성능이 높은 압축 전송을 사용하는 것을 권장한다. 
높은 압축률이 필요하다면 `gzip`, `zstd` 권장하며 빠른 응답 속도가 필요할 때는 `lz4`, `snappy` 를 권장한다.

## 3.2.5 토픽, 파티션, 오프셋

카프카는 **토픽**이라는 곳에 데이터를 저장하는데, 우리가 흔히 사용하는 **이메일 주소** 정도의 개념이다
	병렬 처리를 위해 여러 개의 파티션이라는 단위로 나뉜다.
	-> 단 하나의 토픽이라도 높은 처리량을 수행할 수 있게 된다.

**오프셋**은 파티션의 메시지가 저장되는 위치이며, 순차적으로 증가하는 숫자 형태로 되어 있다.
	-> 고유한 숫자로, 카프카에서는 이를 통해 메시지의 순서를 보장하고 컨슈머에서는 마지막까지 읽은 위치를 알 수도 있다.

![[Pasted image 20240614144541.png]]
	쓰기 라는 `토픽`이 3개의 `파티션`으로 나뉘고, `파티션`마다 순차적으로 증가하는 숫자를 `오프셋` 이라고 한다.

## 3.2.6 고가용성 보장

고가용성을 보장하기 위해 카프카에서는 리플리케이션 기능을 제공한다.

이 **리플레이션 기능**은 토픽 자체를 복제하는 것이 아니라 **토픽의 파티션을 복제하는 것**이다.
	토픽을 생성할 때 옵션으로 리플리케이션 팩터 수를 지정할 수 있으며, 이 숫자에 따라 리플리케이션들이 존재하게 된다.
	원본과 리플리케이션의 구분을 위해 카프카에서는 리더와 팔로워라고 부른다.

![[Pasted image 20240614150920.png]]
	리더의 숫자는 1을 유지한 채 리플리케이션 팩터 수에 따라 팔로워 수가 늘고 잇다.
	-> 팔로워 수가 많을수록 안정적일 수는 있지만, 결국 브로커의 디스크 공간이 소비되므로 이상적인 수를 유지해야 한다. 
	-> 카프카에서는 리플리케이션 팩터 수를 3으로 구성하도록 권장한다.

- **리더**는 프로듀서, 컨슈머로부터 오는 모든 읽기와 쓰기 요청을 처리한다.
- **팔로워**는 오직 리더로부터 리플리케이션하게 된다.

## 3.2.7 주키퍼의 의존성

여러 대의 서버를 앙상블 (클러스터) 로 구성하고, 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능한 구조이다. -> 주키퍼는 반드시 홀수로 구성해야 한다.

지노드 (znode) 를 이용해 카프카의 메타 정보가 주키퍼에 기록되며, `주키퍼`는 이러한 지노드를 이용해 **브로커의 노드 관리, 토픽 관리, 컨트롤러 관리 등 중요한 역할을** 한다.


# 3.3 프로듀서의 기본 동작과 예제 맛보기

## 3.3.1 프로듀서 디자인

![[Pasted image 20240614151349.png]]
	1. `ProducerRecord` 부분은 카프카로 전송하기 위한 실제 데이터 (레코드)이다.
	2. 프로듀서의 `send( )` 메서드를 통해 각 레코드들은 `시리얼라이즈`, `파티셔너`를 거치게 된다. 
		2-1. 레코드에서 선택사항인 파티션을 지정했다면 `파티셔너`는 아무 동작하지 않고 지정된 파티션으로 전달한다.
		2-2. 레코드에서 파티션을 지정하지 않았다면 키를 가지고 파티션을 선택해 레코드를 전달한다. (라운드 로빈 방식으로 동작)
	 -> 프로듀서 내부에서는 `send( )` 메서드 동작 이후 레코드들을 파티션 별로 모아두는데, 이는 프로듀서가 카프카로 전송하기 전 **배치 전송을 하기 위함**이다. 

## 3.3.2 프로듀서의 주요 옵션

![[Pasted image 20240614152243.png]]
![[Pasted image 20240614152257.png]]

## 3.3.3 프로듀서 예제

프로듀서 전송 방법은 `메시지를 보내고 확인하지 않기`, `동기 전송`, `비동기 전송` 이렇게 나눌 수 있다.

### 메세지를 보내고 확인하지 않기 예제 (ProducerFireForgot)
![[Pasted image 20240614154533.png]]
	1. Properties 객체 생성
	2. 브로커 리스트 정의
	3. 메시지 키와 밸류는 문자열 타입이므로 카프카의 기본 `StringSerializer` 지정
	4. Properties 객체를 전달해 새 프로듀서 생성
	5. ProducerRecord 객체 생성
	6. send( ) 메서드를 사용해서 메시지를 전송한 후 자바 Future 객체로 RecordMetadata 를 리턴 받지만, 리턴 값을 무시하므로 메시지가 성공적으로 전송됐는지 알 수 없음
	7. 카프카 브로커에게 메시지를 전송한 후의 에러는 무시하지만, 전송 전에 에러가 발생하면 예외 처리할 수 있음
	8. 프로듀서 종료

### 동기 전송 (ProducerSync.java)

![[Pasted image 20240614164639.png]]
	1. Properties 객체 생성
	2. 브로커 리스트 정의
	3. 메시지 키와 밸류는 문자열 타입이므로 카프카의 기본 `StringSerializer` 지정
	4. Properties 객체를 전달해 새 프로듀서 생성
	5. ProducerRecord 객체 생성
	6. get( ) 메서드를 이용해 카프카의 응답을 기다림, 메시지가 성공적으로 전송되지 않으면 예외 발생, 아니라면 `RecordMetadata` 얻음
	7. 카프카로 메시지를 보내기 전과 보내는 동안 에너가 발생하면 에러 발생
	8. 프로듀서 종료

- 프로듀서는 메시지를 보내고 `send( )` 메서드의 Future 객체를 리턴하며, `get( )` 메서드를 이용해 Future 를 기다린 후 `send( )` 가 성공했는지 실패했는지 여부를 확인한다.
- 일단 `ProducerRecord` 전송이 성공하고 나면 `Record Metadata` 를 읽어들여 파티션과 오프셋 정보를 확인할 수 있으며 메시지 전달의 성공 여부를 파악할 수 있다.

### 콜백예제 (PeterProducerCallback)

![[Pasted image 20240614164247.png]]
	1. 콜백을 사용하기 위해 org.apache.kafka.clients.producer.Callback를 구현하는 클래스가 필요
	2. 카프카가 오류를 리턴하면 onCompletion()은 예외를 갖게 되며, 실제 운영환경에서는 추가적인 예외처리가 필요

### 비동기 전송 (ProducerAsync)

![[Pasted image 20240614164747.png]]
	6. 프로듀서에서 레코드를 보낼 때 콜백 객체를 같이 보낸다.

- 동기 전송과 같이 프로듀서가 보낸 모든 메시지에 대해 응답을 기다리면 많은 시간을 소비하게 되므로 빠른 전송을 할 수 없다. -> 비동기 방식으로 하면 빠른 전송 가능, 메시지 전송이 실패한 경우라도 예외 처리할 수 있어 이후 에러 로그 등에 기록할 수도 있다.


# 3.4 컨슈머의 기본 동작과 예제 맛보기

컨슈머가 단순하게 카프카로부터 메시지만 가져오는 것 같지만, 내부적으로는 컨슈머 그룹, 리밸런싱 등 여러 동작을 수행한다.

## 3.4.1 컨슈머의 기본 동작

> 컨슈머 그룹

컨슈머 그룹은 하나 이상이 컨슈머들이 모여 있는 그룹이며, 컨슈머는 반드시 그룹에 속하게 된다. 그리고 이 그룹은 각 파티션의 리더에게 카프카 토픽에 저장된 메시지를 가져오기 위한 요청을 보낸다. (이때 파티션 수와 컨슈머 수는 일대일 매칭 권장)

## 3.4.2 컨슈머의 주요 옵션

![[Pasted image 20240614165229.png]]
![[Pasted image 20240614165242.png]]

## 3.4.3 컨슈머 예제

컨슈머에서 메시지를 가져오는 방법은 `오토 커밋`, `동기 가져오기`, `비동기 가져오기` 이렇게 나뉜다.

### 오토 커밋 (ConsumerAuto)
: 컨슈머 애플리케이션들이 기본값으로 가장 많이 사용

![[Pasted image 20240614165635.png]]
	1. Properties 객체 생성
	2. 브로커 리스트 정의
	3. 컨슈머 그룹 아이디 정의
	4. 오토 커밋 사용
	5. 컨슈머 오프셋을 찾지 못하는 경우 latest 로 초기화하며 가장 최근부터 메시지를 가져온다.
	6. 문자열을 사용했으므로 `StringDeserializer` 지정
	7. Properties 객체를 전달해 새 컨슈머 생성
	8. 구독할 토픽을 지정
	9. 무한 루프 시작, 메시지를 가져오기 위해 카프카에 지속적으로 poll( ) 을 한다
	10. 컨슈머는 풀링하는 것을 계속 유지하며, 타임아웃 주기를 설정한다. 해당 시간만큼 블록한다.
	11. poll( ) 은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로 반복문 처리
	12. 컨슈머 종료

- 장/단점
	1. 오프셋을 주기적으로 커밋하므로 관리자가 오프셋을 따로 관리하지 않아도 된다.
	2. 컨슈머 종료 등이 빈번하게 일어나면 일부 메시지를 못 가져오거나 중복으로 가져오는 경우가 있다.

### 동기 가져오기 (ConsumerSync)

![[Pasted image 20240614171745.png]]
	1. Properties 객체 생성
	2. 브로커 리스트 정의
	3. 컨슈머 그룹 아이디 정의
	4. 오토 커밋 사용하지 않음
	5. 컨슈머 오프셋을 찾지 못하는 경우 latest 로 초기화, 가장 최근부터 메시지를 가져온다.
	6. 문자열을 사용했으므로 `StringDeserializer` 지정
	7. Properties 객체를 전달해 새 컨슈머 생성
	8. 구독할 토픽을 지정
	9. 무한 루프 시작, 메시지를 가져오기 위해 카프카에 지속적으로 poll( ) 을 한다
	10. 컨슈머는 풀링하는 것을 계속 유지하며, 타임아웃 주기를 설정한다. 해당 시간만큼 블록한다.
	11. poll( ) 은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로 반복문 처리
	12. 현재 배치를 통해 읽은 모든 메시지를 처리한 후, 추가 메시지를 폴링하기 전 현재의 오프셋을 동기 커밋
	13. 컨슈머 종료

- 오토 커밋과 달리 `poll( )` 을 이용해 메시지를 가져온 후 처리까지 완료하고 현재의 오프셋을 커밋한다.
- 속도는 느리지만, 메시지 손실은 거의 발생하지 않는다.
	- **메시지 손실 ?** 토픽에는 메시지가 존재하지만 잘못된 오프셋 커밋으로 인한 위치 변경으로 컨슈머가 메시지를 가져오지 못하는 경우

### 비동기 가져오기 (ConsumerAsync)

![[Pasted image 20240614172145.png]]
	1. Properties 객체 생성
	2. 브로커 리스트 정의
	3. 컨슈머 그룹 아이디 정의
	4. 오토 커밋 사용하지 않음
	5. 컨슈머 오프셋을 찾지 못하는 경우 latest 로 초기화, 가장 최근부터 메시지를 가져온다.
	6. 문자열을 사용했으므로 `StringDeserializer` 지정
	7. Properties 객체를 전달해 새 컨슈머 생성
	8. 구독할 토픽을 지정
	9. 무한 루프 시작, 메시지를 가져오기 위해 카프카에 지속적으로 poll( ) 을 한다
	10. 컨슈머는 풀링하는 것을 계속 유지하며, 타임아웃 주기를 설정한다. 해당 시간만큼 블록한다.
	11. poll( ) 은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로 반복문 처리
	12. 현재 배치를 통해 읽은 모든 메시지를 처리한 후, 추가 메시지를 폴링하기 전 현재의 오프셋을 비동기 커밋
	13. 컨슈머 종료

- **동기 가져오기 vs 비동기 가져오기**
	: `consumer.commitAsync( )` 에 차이가 있다.
	`commitAsync( )` 은 `commitSync( )` 와 달리 오프셋 커밋을 실패하더라도 아래와 같은 이유 때문에 재시도 하지 않는다.
	![[Pasted image 20240614172401.png]] 
	현재 마지막 오프셋은 5인데, 비동기 커밋의 재시도로 인해 2번 오프셋 비동기 커밋이 성공하게 되면 마지막 오프세이 2로 변경되게 된다.
	-> 메시지가 중복되게 된다.

- 비동기 커밋이 실패하더라도 마지막의 비동기 커밋만 성공한다면 안정적으로 오프셋을 커밋하게 된다.

## 3.4.4 컨슈머 그룹의 이해

![[Pasted image 20240614172624.png]]

- 이렇게 컨슈머들은 하나의 컨슈머 그룹 안에 속해 있으며, 그룹 내의 컨슈머들은 서로의 정보를 공유한다. 컨슈머01이 문제가 생겨 종료됐다면 컨슈머 02 혹은 03 이 하던 일을 대신해 동작하게 된다.
